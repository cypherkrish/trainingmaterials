{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c0a852",
   "metadata": {},
   "source": [
    "# Building a PDF Chat System with Gemini 2.0\n",
    "\n",
    "In this notebook, we'll create a simple but powerful PDF chat system using Google's Gemini 2.0 models. This system will allow us to upload PDF documents and have interactive conversations about their contents.\n",
    "\n",
    "## Why Gemini for PDF Processing?\n",
    "\n",
    "Gemini models have several advantages for PDF processing:\n",
    "\n",
    "- Native vision capabilities to understand both text and visuals in documents\n",
    "- Support for long documents (up to 3,600 pages)\n",
    "- Ability to analyze diagrams, charts, and tables\n",
    "- Capability to extract structured information\n",
    "- Support for document summarization and transcription\n",
    "\n",
    "## Setting Up the Environment\n",
    "\n",
    "Let's start by installing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60228247",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c80e2",
   "metadata": {},
   "source": [
    "Now let's import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa901d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import httpx\n",
    "import io\n",
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa58807",
   "metadata": {},
   "source": [
    "## Initialize the Gemini API Client\n",
    "\n",
    "To use the Gemini API, you'll need an API key. If you don't have one yet, you can get it from [Google AI Studio](https://aistudio.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36638509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "GOOGLE_API_KEY = \"YOUR_API_KEY_HERE\"  # Replace with your actual API key\n",
    "# Or load from environment variable\n",
    "# GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize the client\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878f134",
   "metadata": {},
   "source": [
    "## PDF Upload Methods\n",
    "\n",
    "There are two main ways to handle PDFs with Gemini:\n",
    "\n",
    "1. **Direct Upload** (for files < 20MB)\n",
    "2. **File API** (for larger files or when you need to reuse the PDF)\n",
    "\n",
    "Let's implement both methods:\n",
    "\n",
    "### Method 1: Direct Upload (Small PDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eae51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_small_pdf(pdf_path, prompt):\n",
    "    \"\"\"\n",
    "    Process a small PDF file (< 20MB) using direct upload.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file or URL\n",
    "        prompt: Question or instruction for the model\n",
    "        \n",
    "    Returns:\n",
    "        Model response\n",
    "    \"\"\"\n",
    "    # Check if the path is a URL\n",
    "    if pdf_path.startswith(('http://', 'https://')):\n",
    "        # Download the PDF from URL\n",
    "        pdf_data = httpx.get(pdf_path).content\n",
    "    else:\n",
    "        # Read from local file\n",
    "        pdf_data = pathlib.Path(pdf_path).read_bytes()\n",
    "    \n",
    "    # Generate content with the PDF and prompt\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[\n",
    "            types.Part.from_bytes(\n",
    "                data=pdf_data,\n",
    "                mime_type='application/pdf',\n",
    "            ),\n",
    "            prompt\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26db49",
   "metadata": {},
   "source": [
    "### Method 2: File API (Large PDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd618275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_pdf(pdf_path, prompt):\n",
    "    \"\"\"\n",
    "    Process a large PDF file using the File API.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file or URL\n",
    "        prompt: Question or instruction for the model\n",
    "        \n",
    "    Returns:\n",
    "        Model response\n",
    "    \"\"\"\n",
    "    # Check if the path is a URL\n",
    "    if pdf_path.startswith(('http://', 'https://')):\n",
    "        # Download the PDF from URL\n",
    "        pdf_data = io.BytesIO(httpx.get(pdf_path).content)\n",
    "        \n",
    "        # Upload the PDF using the File API\n",
    "        uploaded_file = client.files.upload(\n",
    "            file=pdf_data,\n",
    "            config=dict(mime_type='application/pdf')\n",
    "        )\n",
    "    else:\n",
    "        # Upload the local PDF using the File API\n",
    "        uploaded_file = client.files.upload(\n",
    "            file=pdf_path\n",
    "        )\n",
    "    \n",
    "    # Generate content with the uploaded file and prompt\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[uploaded_file, prompt]\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c253dc7",
   "metadata": {},
   "source": [
    "## Building a Simple PDF Chat Interface\n",
    "\n",
    "Now let's create a simple chat interface for interacting with PDFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFChat:\n",
    "    def __init__(self, pdf_path):\n",
    "        \"\"\"\n",
    "        Initialize the PDF Chat system.\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: Path to the PDF file or URL\n",
    "        \"\"\"\n",
    "        self.pdf_path = pdf_path\n",
    "        \n",
    "        # Determine if it's a large file or URL\n",
    "        if pdf_path.startswith(('http://', 'https://')):\n",
    "            # For URLs, we'll check the file size\n",
    "            try:\n",
    "                head_response = httpx.head(pdf_path)\n",
    "                content_length = int(head_response.headers.get('content-length', 0))\n",
    "                self.is_large = content_length > 20 * 1024 * 1024  # 20MB\n",
    "            except:\n",
    "                # If we can't determine size, assume it's large\n",
    "                self.is_large = True\n",
    "        else:\n",
    "            # For local files, check actual size\n",
    "            file_size = pathlib.Path(pdf_path).stat().st_size\n",
    "            self.is_large = file_size > 20 * 1024 * 1024  # 20MB\n",
    "            \n",
    "        # Upload the file if it's large\n",
    "        if self.is_large:\n",
    "            if pdf_path.startswith(('http://', 'https://')):\n",
    "                pdf_data = io.BytesIO(httpx.get(pdf_path).content)\n",
    "                self.uploaded_file = client.files.upload(\n",
    "                    file=pdf_data,\n",
    "                    config=dict(mime_type='application/pdf')\n",
    "                )\n",
    "            else:\n",
    "                self.uploaded_file = client.files.upload(\n",
    "                    file=pdf_path\n",
    "                )\n",
    "            print(f\"Large PDF uploaded successfully with ID: {self.uploaded_file.name}\")\n",
    "    \n",
    "    def chat(self, prompt):\n",
    "        \"\"\"\n",
    "        Chat with the PDF.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Question or instruction for the model\n",
    "            \n",
    "        Returns:\n",
    "            Model response text\n",
    "        \"\"\"\n",
    "        if self.is_large:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=[self.uploaded_file, prompt]\n",
    "            )\n",
    "        else:\n",
    "            if self.pdf_path.startswith(('http://', 'https://')):\n",
    "                pdf_data = httpx.get(self.pdf_path).content\n",
    "            else:\n",
    "                pdf_data = pathlib.Path(self.pdf_path).read_bytes()\n",
    "                \n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=[\n",
    "                    types.Part.from_bytes(\n",
    "                        data=pdf_data,\n",
    "                        mime_type='application/pdf',\n",
    "                    ),\n",
    "                    prompt\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b957b",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Let's see our PDF Chat system in action with some example use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Chat with a small PDF from a URL\n",
    "pdf_url = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"\n",
    "pdf_chat = PDFChat(pdf_url)\n",
    "\n",
    "# Get a summary of the document\n",
    "summary = pdf_chat.chat(\"Summarize this document in 5 bullet points\")\n",
    "print(\"Document Summary:\")\n",
    "print(summary)\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Ask specific questions about the content\n",
    "answer = pdf_chat.chat(\"What are the main findings or conclusions of this paper?\")\n",
    "print(\"Main Findings:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb8c66",
   "metadata": {},
   "source": [
    "python\n",
    "# Example 2: Chat with a large NASA document\n",
    "nasa_pdf = \"https://www.nasa.gov/wp-content/uploads/static/history/alsj/a17/A17_FlightPlan.pdf\"\n",
    "nasa_chat = PDFChat(nasa_pdf)\n",
    "\n",
    "# Ask about the mission objectives\n",
    "mission = nasa_chat.chat(\"What were the main mission objectives described in this document?\")\n",
    "print(\"Mission Objectives:\")\n",
    "print(mission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Advanced Use Cases\n",
    "\n",
    "### 1. Extracting Structured Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3d297",
   "metadata": {},
   "source": [
    "python\n",
    "# Extract information in a structured format\n",
    "structured_info = pdf_chat.chat(\"Extract the key figures and statistics from this document and format them as a JSON object\")\n",
    "print(\"Structured Information:\")\n",
    "print(structured_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be380f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Analyzing Charts and Diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b62571",
   "metadata": {},
   "source": [
    "python\n",
    "# Analyze charts or diagrams in the document\n",
    "chart_analysis = pdf_chat.chat(\"Describe any charts, graphs, or diagrams in the document and explain what they show\")\n",
    "print(\"Chart Analysis:\")\n",
    "print(chart_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89690eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. Comparing Multiple PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1b65d",
   "metadata": {},
   "source": [
    "python\n",
    "# Function to compare two PDFs\n",
    "def compare_pdfs(pdf_url_1, pdf_url_2, comparison_prompt):\n",
    "    # Upload both PDFs using File API\n",
    "    pdf_data_1 = io.BytesIO(httpx.get(pdf_url_1).content)\n",
    "    pdf_data_2 = io.BytesIO(httpx.get(pdf_url_2).content)\n",
    "    \n",
    "    uploaded_pdf_1 = client.files.upload(\n",
    "        file=pdf_data_1,\n",
    "        config=dict(mime_type='application/pdf')\n",
    "    )\n",
    "    \n",
    "    uploaded_pdf_2 = client.files.upload(\n",
    "        file=pdf_data_2,\n",
    "        config=dict(mime_type='application/pdf')\n",
    "    )\n",
    "    \n",
    "    # Generate comparison\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[uploaded_pdf_1, uploaded_pdf_2, comparison_prompt]\n",
    "    )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "# Example usage\n",
    "pdf_url_1 = \"https://arxiv.org/pdf/2312.11805\"  # Gemini paper\n",
    "pdf_url_2 = \"https://arxiv.org/pdf/2403.05530\"  # Another AI paper\n",
    "\n",
    "comparison = compare_pdfs(\n",
    "    pdf_url_1, \n",
    "    pdf_url_2, \n",
    "    \"What are the key differences between these two papers? Organize your answer in a table.\"\n",
    ")\n",
    "print(\"PDF Comparison:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best Practices for Working with PDFs\n",
    "\n",
    "1. **Document Preparation**:\n",
    "   - Ensure PDFs are correctly rotated\n",
    "   - Use clear, non-blurry documents for best results\n",
    "   - For scanned documents, ensure good image quality\n",
    "\n",
    "2. **Prompt Engineering**:\n",
    "   - Be specific about the section or page you're interested in\n",
    "   - For long documents, use \"Find in the document...\" style prompts\n",
    "   - Request structured outputs (tables, JSON) for easier parsing\n",
    "\n",
    "3. **Performance Optimization**:\n",
    "   - Use File API for PDFs larger than 20MB\n",
    "   - Reuse uploaded files for multiple queries about the same document\n",
    "   - Consider extracting only relevant pages for faster processing\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- While Gemini supports up to 3,600 pages, very large documents may be processed less accurately\n",
    "- Complex layouts, low-quality scans, or handwritten text may reduce accuracy\n",
    "- Performance may vary with highly technical or specialized content\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we've built a simple yet powerful PDF chat system using Gemini 2.0. This system allows us to upload PDFs of various sizes and have interactive conversations about their contents. We've also explored several advanced use cases and best practices for working with PDF documents.\n",
    "\n",
    "With Gemini's multimodal capabilities, you can understand not just the text but also the visual elements in your documents, making it an excellent tool for document understanding and analysis."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
